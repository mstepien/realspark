# generated by datamodel-codegen:
#   filename:  openapi.yaml
#   timestamp: 2026-01-20T15:56:56+00:00

from __future__ import annotations

from typing import Any

from pydantic import BaseModel, Field


class UploadResponse(BaseModel):
    task_id: str


class MetadataAnalysis(BaseModel):
    tags: dict[str, str] | None = Field(
        None, description='Key-value pairs of extracted metadata tags.'
    )
    description: str | None = Field(
        None, description='A summary or analysis of the metadata findings.'
    )
    is_suspicious: bool | None = None


class ArtMediumAnalysis(BaseModel):
    medium: str | None = None
    confidence: float | None = None
    consistency_score: float | None = None
    description: str | None = None
    labels_weighted: dict[str, float] | None = None


class Box(BaseModel):
    xmin: float | None = None
    ymin: float | None = None
    xmax: float | None = None
    ymax: float | None = None


class ObjectDetectionItem(BaseModel):
    label: str | None = None
    score: float | None = None
    box: Box | None = None


class ImageStats(BaseModel):
    summary: str | None = None
    width: int | None = None
    height: int | None = None
    mean_color: list[float] | None = None
    ai_probability: float | None = None
    fd_default: float | None = Field(
        None, description='Fractal dimension calculated over the full box range.'
    )
    metadata_analysis: MetadataAnalysis | None = Field(
        None, description='Results of the image metadata examination.'
    )
    art_medium_analysis: ArtMediumAnalysis | None = Field(
        None, description='Results of the DINOv2 and CLIP basis art medium analysis.'
    )
    object_detection: list[ObjectDetectionItem] | None = None


class StatEntry(BaseModel):
    label: str | None = None
    count: int | None = None


class Result(BaseModel):
    id: str | None = None
    url: str | None = None
    stats: ImageStats | None = None


class TaskStatus(BaseModel):
    status: str = Field(
        ...,
        description='Current status (Starting..., Preprocessing..., Performing Parallel Analysis & Upload..., Saving to Database..., Complete, Error, Abandoned)',
    )
    progress: int
    steps: list[str]
    current_step: str | None = None
    completed_steps: list[str]
    timed_out_steps: list[str] = Field(
        ..., description='List of steps that timed out during analysis.'
    )
    partial_results: dict[str, Any] | None = None
    result: Result | None = None
    error: str | None = Field(
        None,
        description='Error message if the task failed (e.g., due to analysis error or process timeout).',
    )


class AggregateStats(BaseModel):
    total_images: int
    avg_width: float | None = None
    avg_height: float | None = None
    avg_color: list[float] | None = None
    ai_metadata: list[StatEntry] | None = None
    human_metadata: list[StatEntry] | None = None
    art_mediums: list[StatEntry] | None = None
    fractal_dist: list[StatEntry] | None = None
